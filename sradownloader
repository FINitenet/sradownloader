#!/usr/bin/env python3

#############################################################################
#    Copyright 2020 Simon Andrews
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
############################################################################


import sys
import subprocess
import os
import csv
import argparse
import glob
import urllib.request
import re

VERSION = "1.1.devel"


# These are the symbols we're going to need to remove
# from any proposed file names
invalid_charachters = [" ","/",">","<","|","\"","?","*"]


def download_sample (sample, options):
    if not options.quiet:
        print (f"Downloading {sample['accession']} into {sample['file_base']}", flush=True)

    command_options = [options.fqdump,"--split-files","--threads",options.threads,"--outfile",sample["file_base"]]
    
    # If they're attached to a terminal and they're not being quiet then we'll show progress

    if not options.quiet:
        if sys.stdin.isatty():
            # NB: NCBI can't spell.  They inadvertently changed --progress to --progres and it's been
            # like that for a while. We had to add an option to mis-spell the progress option
            if options.cantspell:
                command_options.append("--progres")
            else:
                command_options.append("--progress")
    
    # If they're not using the current directory as output we'll say where it should go
    if options.outdir != ".":
        command_options.append("--outdir")
        command_options.append(options.outdir)

    
    # Finally add the accession
    command_options.append(sample['accession'])
    
    command_options = [str(x) for x in command_options]

    attempt_number = 1

    while (attempt_number <= options.retries):
        if not options.quiet:
            print(f"[Attempt {attempt_number}] Running: "+" ".join(command_options), flush=True)

        result = subprocess.run(command_options, check=False)

        if result.returncode != 0:
            if attempt_number == options.retries:
                attempt_number += 1
                print(f"Sorry SRAtoolkit just isn't having it, giving up on this accession", flush=True)
                break

            else:
                print(f"SRAtoolkit failed us - going around for another try", flush=True)
                attempt_number += 1
                continue

    if attempt_number > options.retries:
        # This failed so don't try to do anything else with it
        return

    # Now find the files which were created and compress them
    downloaded_files = glob.glob(options.outdir+"/"+sample['file_base']+"*.fastq")

    if len(downloaded_files) == 0:
        print ("ERROR: Got no files for accession "+sample['accession'], file=sys.stderr, flush=True)

    for file in downloaded_files:
        if not options.quiet:
                print("Compressing "+file, flush=True)

        subprocess.run(["gzip","-4",file], check=True)


def read_samples (options):
    if not options.quiet:
        print(f"Reading samples from {options.runtable}", flush=True)

    sample_file = options.runtable
    samples = []
    headers = []
    name_index = 0
    with open(sample_file) as fh:
        csv_fh = csv.reader(fh)
        for sections in csv_fh:
            if len(headers) == 0:
                headers = sections
                if "source_name" in headers:
                    name_index = headers.index("source_name")
                else:
                    name_index = -1                
                continue

            sample_name = ""

            # See if we need to look up a nice name from GEO (SRA)
            if not options.nogeo :
                if not options.quiet:
                    print(f"Trying to get name for {sections[0]} from GEO - (stop this with --nogeo)", flush=True)
                with urllib.request.urlopen(f"https://www.ncbi.nlm.nih.gov/sra/?term={sections[0]}&format=text") as response:
                    for line in response:
                        line = line.decode("UTF-8")
                        if line.startswith("Title:"):
                            geosections = re.split("[:;] ",line)

                            sample_name = "_".join(geosections[1:])
                            break

            if sample_name == "":
                if name_index >= 0:
                    sample_name = sections[name_index].strip()


            for bad_char in invalid_charachters:
                sample_name = sample_name.replace(bad_char,"_")

            sample_name = "_"+sample_name



            if not options.quiet:
                print (f"Found sample {sections[0]} with basename {sections[0]}{sample_name}", flush=True)

            sample = {
                "accession" : sections[0],
                "file_base" : sections[0] + sample_name
            }

            samples.append(sample)
    
    return samples

def read_options():
    parser = argparse.ArgumentParser(description="Download data from the SRA")

    parser.add_argument('--quiet', dest="quiet", action='store_true', default=False, help="Supress all but essential messages")
    parser.add_argument('--version', action='version', version=f"SRA downloader v{VERSION}")
    parser.add_argument('--outdir', type=str, help="Folder to save data to (default .)", default=".")
    parser.add_argument('--threads', type=int, help="Number of threads (default 1)", default=1)
    parser.add_argument('--retries', type=int, help="Number of times we'll retry a download before giving up (default 5)", default=5)
    parser.add_argument('--fqdump', type=str, help="Path to the fastq dump program (default fasterq-dump)", default="fasterq-dump")
    parser.add_argument('--cantspell', dest="cantspell", action='store_true', help="Change --progress to --progres because of a bug in some fasterq-dump releases")
    parser.add_argument('--nogeo', dest="nogeo", action='store_true', help="Disable sample name lookup from GEO")
    parser.add_argument('runtable', type=str, help="The SraRunTable.txt file from the SRA run selector")

    options = parser.parse_args()

    # Can we find fasterq-dump
    if not options.quiet:
        print("Testing for fasterq-dump at "+options.fqdump, flush=True)

    try:
        subprocess.run([options.fqdump,"--version"], check=True, stdout=subprocess.DEVNULL)

        if not options.quiet:
            print("Found fasterq-dump at "+options.fqdump, flush=True)

    except:
        print ("ERROR: Couldn't find fasterq-dump at "+options.fqdump+". Please ensure that sratoolkit is downloaded and that you've run vdb-config", file=sys.stderr, flush=True)
        sys.exit(1)


    # Can we find gzip
    if not options.quiet:
        print("Testing for gzip in the path", flush=True)

    try:
        subprocess.run(["gzip","--version"], check=True, stdout=subprocess.DEVNULL)

        if not options.quiet:
            print("Found gzip", flush=True)

    except:
        print ("ERROR: Couldn't find gzip in the path", file=sys.stderr, flush=True)
        sys.exit(1)




    return options


def main():
    options = read_options()
    samples = read_samples(options)
    for sample in samples:
        download_sample(sample,options)

if __name__ == "__main__":
    main()