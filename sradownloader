#!/usr/bin/env python3

#############################################################################
#    Copyright 2020 Simon Andrews
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
############################################################################


import sys
import subprocess
import os
import csv
import argparse
import glob
import urllib.request
import re
import shutil

VERSION = "3.0.devel"

# These are the symbols we're going to need to remove
# from any proposed file names
invalid_characters = [" ","/",">","<","|","\"","?","*","(",")","\\","[","]","{","}","!"]


def download_sample_ena (sample, options):
    if not options.quiet:
        print (f"[ENA] Downloading {sample['accession']} into {sample['file_base']}", flush=True)

    # Get the FTP locations for the sample
    ena_rest_url = f"https://www.ebi.ac.uk/ena/portal/api/filereport?accession={sample['accession']}&result=read_run&fields=run_accession,fastq_ftp"

    print(f"URL is '{ena_rest_url}'")

    with urllib.request.urlopen(ena_rest_url) as response:
        for line in response:
            line = line.decode("UTF-8").strip()
            if line.startswith("SRR"):
                sections = line.split("\t")

                if len(sections) != 2:
                    raise IOError(f"No ENA fastq files found for accession {sample['accession']}")

                url_list = sections[1].split(";")
                break

    for url in url_list:

        # Work out the output file name.  We're assuming there's never
        # going to be more than 2 files per sample
        if url.endswith("_2.fastq.gz"):
            outfile=sample['file_base'] + "_2.fastq.gz"

        else:
            outfile=sample['file_base'] + "_1.fastq.gz"


        if not options.quiet:
            print (f"[ENA] Downloading {url} into {outfile}", flush=True)
        
        with urllib.request.urlopen("http://"+url) as response, open(outfile, 'wb') as out_file:
            shutil.copyfileobj(response, out_file)


def download_sample_ncbi (sample, options):
    if not options.quiet:
        print (f"[NCBI] Downloading {sample['accession']} into {sample['file_base']}", flush=True)

    command_options = [options.fqdump,"--split-files","--threads",options.threads,"--outfile",sample["file_base"]+".fastq"]
    
    # If they're attached to a terminal and they're not being quiet then we'll show progress

    if not options.quiet:
        if sys.stdin.isatty():
            command_options.append("--progress")
    
    # If they're not using the current directory as output we'll say where it should go
    if options.outdir != ".":
        command_options.append("--outdir")
        command_options.append(options.outdir)

    # Finally add the accession
    command_options.append(sample['accession'])
    
    command_options = [str(x) for x in command_options]

    attempt_number = 1

    while (attempt_number <= options.retries):
        if not options.quiet:
            print(f"[Attempt {attempt_number}] Running: "+" ".join(command_options), flush=True)

        result = subprocess.run(command_options, check=False)

        if result.returncode != 0:
            if attempt_number == options.retries:
                attempt_number += 1
                print(f"Sorry SRAtoolkit just isn't having it, giving up on this accession", flush=True)
                break

            else:
                print(f"SRAtoolkit failed us - going around for another try", flush=True)
                attempt_number += 1
                continue

        else:
            # Amazingly it worked
            break

    if attempt_number > options.retries:
        # This failed so don't try to do anything else with it
        return

    # Now find the files which were created and compress them
    downloaded_files = glob.glob(options.outdir+"/"+sample['file_base']+"*.fastq")

    if len(downloaded_files) == 0:
        print ("ERROR: Got no files for accession "+sample['accession'], file=sys.stderr, flush=True)

    for file in downloaded_files:
        if not options.quiet:
                print("Compressing "+file, flush=True)

        subprocess.run(["gzip","-4",file], check=True)


def read_samples (options):
    if not options.quiet:
        print(f"Reading samples from {options.runtable}", flush=True)

    sample_file = options.runtable
    samples = []
    headers = []
    name_index = 0
    with open(sample_file) as fh:
        csv_fh = csv.reader(fh)
        for sections in csv_fh:
            if len(headers) == 0:
                headers = sections
                if "source_name" in headers:
                    name_index = headers.index("source_name")
                else:
                    name_index = -1                
                continue

            sample_name = ""

            # See if we need to look up a nice name from GEO (SRA)
            if not options.nogeo :
                if not options.quiet:
                    print(f"Trying to get name for {sections[0]} from GEO - (stop this with --nogeo)", flush=True)
                with urllib.request.urlopen(f"https://www.ncbi.nlm.nih.gov/sra/?term={sections[0]}&format=text") as response:
                    for line in response:
                        line = line.decode("UTF-8")
                        if line.startswith("Title:"):
                            line = line.strip()
                            geosections = re.split("[:;] ",line)

                            sample_name = "_".join(geosections[1:])
                            break

            if sample_name == "":
                if name_index >= 0:
                    sample_name = sections[name_index].strip()


            for bad_char in invalid_characters:
                sample_name = sample_name.replace(bad_char,"_")

            # Add a leading underscore to separate it from the accession
            sample_name = "_"+sample_name

            # Clean up any runs of underscores
            while "__" in sample_name:
                sample_name = sample_name.replace("__","_")

            if not options.quiet:
                print (f"Found sample {sections[0]} with basename {sections[0]}{sample_name}", flush=True)

            sample = {
                "accession" : sections[0],
                "file_base" : sections[0] + sample_name
            }

            samples.append(sample)
    
    return samples

def read_options():
    parser = argparse.ArgumentParser(description="Download data from the SRA")

    parser.add_argument('--quiet', dest="quiet", action='store_true', default=False, help="Supress all but essential messages")
    parser.add_argument('--version', action='version', version=f"SRA downloader v{VERSION}")
    parser.add_argument('--outdir', type=str, help="Folder to save data to (default .)", default=".")
    parser.add_argument('--threads', type=int, help="Number of threads (default 1)", default=1)
    parser.add_argument('--retries', type=int, help="Number of times we'll retry a download before giving up (default 5)", default=5)
    parser.add_argument('--fqdump', type=str, help="Path to the fastq dump program (default fasterq-dump)", default="fasterq-dump")
    parser.add_argument('--nogeo', dest="nogeo", action='store_true', help="Disable sample name lookup from GEO")
    parser.add_argument('runtable', type=str, help="The SraRunTable.txt file from the SRA run selector")

    options = parser.parse_args()

    # Can we find fasterq-dump
    if not options.quiet:
        print("Testing for fasterq-dump at "+options.fqdump, flush=True)

    try:
        subprocess.run([options.fqdump,"--version"], check=True, stdout=subprocess.DEVNULL)

        if not options.quiet:
            print("Found fasterq-dump at "+options.fqdump, flush=True)

    except:
        print ("ERROR: Couldn't find fasterq-dump at "+options.fqdump+". Please ensure that sratoolkit is downloaded and that you've run vdb-config", file=sys.stderr, flush=True)
        sys.exit(1)


    # Can we find gzip
    if not options.quiet:
        print("Testing for gzip in the path", flush=True)

    try:
        subprocess.run(["gzip","--version"], check=True, stdout=subprocess.DEVNULL)

        if not options.quiet:
            print("Found gzip", flush=True)

    except:
        print ("ERROR: Couldn't find gzip in the path", file=sys.stderr, flush=True)
        sys.exit(1)




    return options


def main():
    options = read_options()
    samples = read_samples(options)
    for sample in samples:
        try:
            download_sample_ena(sample,options)

        except Exception as ex:
            print(f"Failed to download via ENA: {ex} trying NCBI instead", file=sys.stderr, flush=True)
            download_sample_ncbi(sample, options)

if __name__ == "__main__":
    main()